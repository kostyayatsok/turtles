{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- single head\n",
        "- sgd\n",
        "- all classes"
      ],
      "metadata": {
        "id": "-eWtjzNCda_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMhZ1PFOEG5J",
        "outputId": "5379e0b2-01b0-4b7e-e589-80d0650f374d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'turtles'...\n",
            "remote: Enumerating objects: 285, done.\u001b[K\n",
            "remote: Counting objects: 100% (285/285), done.\u001b[K\n",
            "remote: Compressing objects: 100% (212/212), done.\u001b[K\n",
            "remote: Total 285 (delta 146), reused 196 (delta 64), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (285/285), 189.26 MiB | 21.36 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n",
            "Checking out files: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://kostyayatsok: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@github.com/kostyayatsok/turtles.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuWeBlKzE7zG",
        "outputId": "6b5c1db9-bcf2-4af3-de8f-0c176d1e422e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/turtles\n"
          ]
        }
      ],
      "source": [
        "%cd turtles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzIEVh-3NWs8",
        "outputId": "51950a2f-ae35-463a-e237-a48f4da30d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at acf0546 fix train_view mode\n"
          ]
        }
      ],
      "source": [
        "!git reset --hard $HEAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpb93Ya4IkCD",
        "outputId": "855251a5-1ff9-4cb5-9194-24665a0fe76f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/kostyayatsok/turtles\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   4adc889..5de9244  main       -> origin/main\n",
            "hint: Waiting for your editor to close the file... error: unable to start editor 'editor'\n",
            "Not committing merge; use 'git commit' to complete the merge.\n"
          ]
        }
      ],
      "source": [
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN2yC27tTh16",
        "outputId": "e78e2827-53f0-4b5c-be80-0056d3faffef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 12.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 50.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U38XgEiE9cz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdc9b70-6657-4867-86e2-d559becba3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.10.0+cu111\n",
            "Torchvision Version:  0.11.1+cu111\n",
            "Using (1501, 4) images for training and (644, 4) images for validation\n",
            "--2022-03-20 09:58:03--  https://storage.googleapis.com/dm-turtle-recall/images.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 173.194.218.128, 108.177.11.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6481244160 (6.0G) [application/x-tar]\n",
            "Saving to: ‘./turtle_recall/images/images.tar’\n",
            "\n",
            "./turtle_recall/ima 100%[===================>]   6.04G   147MB/s    in 56s     \n",
            "\n",
            "2022-03-20 09:59:00 (110 MB/s) - ‘./turtle_recall/images/images.tar’ saved [6481244160/6481244160]\n",
            "\n",
            "The total number of images is: 13891\n",
            "(1501, 4) (644, 4) (490, 2)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 128MB/s]\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --mode train_views"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlvWQyAnAHX8",
        "outputId": "3330e47f-99a6-48f6-ca04-fa68c553c2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.10.0+cu111\n",
            "Torchvision Version:  0.11.1+cu111\n",
            "Using (1501, 4) images for training and (644, 4) images for validation\n",
            "(1501, 4) (644, 4) (490, 2)\n",
            "The total number of images is: 13891\n",
            "Epoch 0/1\n",
            "----------\n",
            "100% 188/188 [00:48<00:00,  3.90it/s]\n",
            "train Loss: 0.3631 Acc: 0.8787\n",
            "100% 81/81 [00:19<00:00,  4.06it/s]\n",
            "val Loss: 0.2261 Acc: 0.9394\n",
            "\n",
            "Epoch 1/1\n",
            "----------\n",
            "100% 188/188 [00:50<00:00,  3.69it/s]\n",
            "train Loss: 0.1686 Acc: 0.9500\n",
            "100% 81/81 [00:23<00:00,  3.42it/s]\n",
            "val Loss: 0.2850 Acc: 0.9394\n",
            "\n",
            "Training complete in 2m 23s\n",
            "Best val Acc: 0.939441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py \\\n",
        "    --mode train \\\n",
        "    --use_extra_data \\\n",
        "    --new_turtles_fraq 0.05 \\\n",
        "    # --checkpoint checkpoints/model.pt\n",
        "    # --use_extra_ids \\\n",
        "    # --views_model checkpoints/model_views.pt \\\n",
        "    # --wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fogQk_2NP3wO",
        "outputId": "e0a2597f-46ad-410e-db4f-8ed95d6133ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.10.0+cu111\n",
            "Torchvision Version:  0.11.1+cu111\n",
            "The total number of images is: 13891\n",
            "Add 107 new_turtles\n",
            "Using (2601, 4) images for training and (290, 4) images for validation\n",
            "(2601, 4) (290, 4) (490, 2)\n",
            "Epoch 0/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.50it/s]\n",
            "train Loss: 4.2569 Acc: 0.0815\n",
            "100% 37/37 [00:09<00:00,  3.91it/s]\n",
            "val Loss: 3.8320 Acc: 0.1310\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.50it/s]\n",
            "train Loss: 3.3774 Acc: 0.2380\n",
            "100% 37/37 [00:09<00:00,  3.83it/s]\n",
            "val Loss: 2.9744 Acc: 0.2897\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "100% 326/326 [01:34<00:00,  3.46it/s]\n",
            "train Loss: 2.6066 Acc: 0.3860\n",
            "100% 37/37 [00:09<00:00,  3.90it/s]\n",
            "val Loss: 2.3847 Acc: 0.4379\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.54it/s]\n",
            "train Loss: 1.9690 Acc: 0.5356\n",
            "100% 37/37 [00:09<00:00,  3.94it/s]\n",
            "val Loss: 2.0872 Acc: 0.4966\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.52it/s]\n",
            "train Loss: 1.5069 Acc: 0.6517\n",
            "100% 37/37 [00:09<00:00,  3.82it/s]\n",
            "val Loss: 1.6444 Acc: 0.5862\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.54it/s]\n",
            "train Loss: 1.2144 Acc: 0.7247\n",
            "100% 37/37 [00:09<00:00,  3.79it/s]\n",
            "val Loss: 1.3800 Acc: 0.6552\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.54it/s]\n",
            "train Loss: 0.9403 Acc: 0.8012\n",
            "100% 37/37 [00:09<00:00,  4.02it/s]\n",
            "val Loss: 1.2665 Acc: 0.6793\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "100% 326/326 [01:30<00:00,  3.58it/s]\n",
            "train Loss: 0.7534 Acc: 0.8393\n",
            "100% 37/37 [00:09<00:00,  3.92it/s]\n",
            "val Loss: 1.2269 Acc: 0.6759\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.54it/s]\n",
            "train Loss: 0.5945 Acc: 0.8854\n",
            "100% 37/37 [00:09<00:00,  3.75it/s]\n",
            "val Loss: 1.1133 Acc: 0.7207\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "100% 326/326 [01:31<00:00,  3.56it/s]\n",
            "train Loss: 0.4609 Acc: 0.9208\n",
            "100% 37/37 [00:09<00:00,  4.01it/s]\n",
            "val Loss: 1.0140 Acc: 0.7517\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "100% 326/326 [01:31<00:00,  3.56it/s]\n",
            "train Loss: 0.3669 Acc: 0.9435\n",
            "100% 37/37 [00:09<00:00,  3.80it/s]\n",
            "val Loss: 0.9252 Acc: 0.7897\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "100% 326/326 [01:31<00:00,  3.58it/s]\n",
            "train Loss: 0.3026 Acc: 0.9500\n",
            "100% 37/37 [00:09<00:00,  4.08it/s]\n",
            "val Loss: 0.8772 Acc: 0.7793\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "100% 326/326 [01:31<00:00,  3.57it/s]\n",
            "train Loss: 0.2650 Acc: 0.9569\n",
            "100% 37/37 [00:09<00:00,  3.97it/s]\n",
            "val Loss: 0.7621 Acc: 0.8207\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.53it/s]\n",
            "train Loss: 0.2013 Acc: 0.9735\n",
            "100% 37/37 [00:09<00:00,  3.92it/s]\n",
            "val Loss: 0.7809 Acc: 0.8069\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.53it/s]\n",
            "train Loss: 0.1905 Acc: 0.9708\n",
            "100% 37/37 [00:09<00:00,  3.93it/s]\n",
            "val Loss: 0.7259 Acc: 0.8172\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.50it/s]\n",
            "train Loss: 0.1549 Acc: 0.9746\n",
            "100% 37/37 [00:09<00:00,  3.99it/s]\n",
            "val Loss: 0.8414 Acc: 0.7828\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.54it/s]\n",
            "train Loss: 0.1398 Acc: 0.9835\n",
            "100% 37/37 [00:09<00:00,  3.87it/s]\n",
            "val Loss: 0.7295 Acc: 0.8207\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.51it/s]\n",
            "train Loss: 0.1366 Acc: 0.9792\n",
            "100% 37/37 [00:09<00:00,  4.00it/s]\n",
            "val Loss: 0.7730 Acc: 0.7966\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "100% 326/326 [01:31<00:00,  3.55it/s]\n",
            "train Loss: 0.1205 Acc: 0.9881\n",
            "100% 37/37 [00:09<00:00,  4.08it/s]\n",
            "val Loss: 0.7103 Acc: 0.8207\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.51it/s]\n",
            "train Loss: 0.1008 Acc: 0.9885\n",
            "100% 37/37 [00:09<00:00,  4.00it/s]\n",
            "val Loss: 0.6721 Acc: 0.8310\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.49it/s]\n",
            "train Loss: 0.0850 Acc: 0.9931\n",
            "100% 37/37 [00:09<00:00,  3.91it/s]\n",
            "val Loss: 0.6963 Acc: 0.8310\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.51it/s]\n",
            "train Loss: 0.0897 Acc: 0.9877\n",
            "100% 37/37 [00:09<00:00,  3.98it/s]\n",
            "val Loss: 0.7043 Acc: 0.8207\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.48it/s]\n",
            "train Loss: 0.0820 Acc: 0.9892\n",
            "100% 37/37 [00:09<00:00,  3.99it/s]\n",
            "val Loss: 0.6875 Acc: 0.8379\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "100% 326/326 [01:32<00:00,  3.51it/s]\n",
            "train Loss: 0.0746 Acc: 0.9919\n",
            "100% 37/37 [00:09<00:00,  4.01it/s]\n",
            "val Loss: 0.5927 Acc: 0.8448\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.48it/s]\n",
            "train Loss: 0.0734 Acc: 0.9900\n",
            "100% 37/37 [00:09<00:00,  3.96it/s]\n",
            "val Loss: 0.6217 Acc: 0.8345\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.48it/s]\n",
            "train Loss: 0.0620 Acc: 0.9927\n",
            "100% 37/37 [00:09<00:00,  3.98it/s]\n",
            "val Loss: 0.6077 Acc: 0.8345\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.49it/s]\n",
            "train Loss: 0.0527 Acc: 0.9946\n",
            "100% 37/37 [00:09<00:00,  4.01it/s]\n",
            "val Loss: 0.5828 Acc: 0.8414\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.49it/s]\n",
            "train Loss: 0.0534 Acc: 0.9942\n",
            "100% 37/37 [00:09<00:00,  3.99it/s]\n",
            "val Loss: 0.6132 Acc: 0.8414\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "100% 326/326 [01:33<00:00,  3.50it/s]\n",
            "train Loss: 0.0450 Acc: 0.9962\n",
            "100% 37/37 [00:08<00:00,  4.12it/s]\n",
            "val Loss: 0.5130 Acc: 0.8655\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "100% 326/326 [01:31<00:00,  3.57it/s]\n",
            "train Loss: 0.0531 Acc: 0.9931\n",
            "100% 37/37 [00:09<00:00,  3.99it/s]\n",
            "val Loss: 0.5092 Acc: 0.8552\n",
            "\n",
            "Training complete in 51m 8s\n",
            "Best val Acc: 0.865517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 submission.py \\\n",
        "    --checkpoint checkpoints/model.pt \\\n",
        "    # --views_model checkpoints/model_views.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we2NnhJ76qTU",
        "outputId": "914589b1-9e77-4a7f-d483-fd8603a73ff4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.10.0+cu111\n",
            "Torchvision Version:  0.11.1+cu111\n",
            "The total number of images is: 13891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/turtles/submission_turtles.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7HOEvi54N1ds",
        "outputId": "5828c20c-4809-4db4-bba6-1ca8fe4302cb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c95f3545-d57f-4a62-88bc-2b24c89426dc\", \"submission_turtles.csv\", 40027)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "ZH2hb3T7UhVy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git config --global user.email \"kielenik@edu.hse.ru\"\n",
        "! git config --global user.name \"kostyayatsok\""
      ],
      "metadata": {
        "id": "nrIyHNtA3H6e"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"42 seed densnet; Best val Acc: 0.776498\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTUi48ehVoOR",
        "outputId": "93db106f-3e79-489d-a787-ba5908792dfd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 9f12f05] 42 seed densnet; Best val Acc: 0.776498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4VdvFGFUjsm",
        "outputId": "e29d7dd2-f2cf-4df6-a9cc-5001f3229c48"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting objects: 10, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (10/10), done.\n",
            "Writing objects: 100% (10/10), 25.59 MiB | 9.41 MiB/s, done.\n",
            "Total 10 (delta 6), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (6/6), completed with 5 local objects.\u001b[K\n",
            "To https://github.com/kostyayatsok/turtles.git\n",
            "   5de9244..9f12f05  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPGldrPGY8fB"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download(\"/content/turtles/checkpoints/improved-net.pt\")\n",
        "# # files.download(\"/content/turtles/checkpoints/model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSXnRkFIm7aE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd09c1f7-0cbb-4219-fccd-b8ec3ac9c1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.10.0+cu111\n",
            "Torchvision Version:  0.11.1+cu111\n",
            "Using (1501, 4) images for training and (644, 4) images for validation\n",
            "The total number of images is: 13891\n",
            "(1501, 4) (644, 4) (490, 2)\n",
            "100% 188/188 [00:50<00:00,  3.71it/s]\n",
            "Phase train Loss: 0.0033 Acc: 1.0000 Map5: 1.0000 Map1: 1.0000\n",
            "100% 81/81 [00:22<00:00,  3.57it/s]\n",
            "Phase val Loss: 3.0426 Acc: 0.3696 Map5: 0.4466 Map1: 0.3696\n"
          ]
        }
      ],
      "source": [
        "from config import CHECKPOINTS_DIR\n",
        "!python3 train.py --mode eval --checkpoint {CHECKPOINTS_DIR}/model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tBpFrdR3U3O"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "# files.download(\"/content/turtles/checkpoints/improved-net.pt\")\n",
        "files.download(\"/content/turtles/checkpoints/model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMKgOVtvykB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7997f84f-eeac-4aaa-bcca-508e35e1341d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'checkpoints/improved-net.pt': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! cp checkpoints/improved-net.pt ./ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzjL2bdgXaXA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "9ac5bab6-aac9-430a-c40b-60f6605d12eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3ccb902dec1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_val_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "from src.model import get_model\n",
        "from config import *\n",
        "import torch\n",
        "from src.data import load_csv, train_val_split\n",
        "\n",
        "train, test = load_csv()\n",
        "train = train.reset_index()\n",
        "train, val = train_val_split(train, 0.7)\n",
        "\n",
        "model = get_model(num_classes)\n",
        "model.load_state_dict(torch.load(\"./improved-net.pt\"))\n",
        "model.load_state_dict(torch.load(\"../model.pt\"))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# for m in model.modules():\n",
        "#     if isinstance(m, torch.nn.BatchNorm2d):\n",
        "#         print(m.running_mean)\n",
        "\n",
        "# model(torch.randn(2, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akQnbUtgkeer"
      },
      "outputs": [],
      "source": [
        "from byol_pytorch import BYOL\n",
        "\n",
        "learner = BYOL(\n",
        "        model,\n",
        "        image_size = input_size,\n",
        "        hidden_layer = 'avgpool',\n",
        "        use_momentum=False,\n",
        "    )\n",
        "# _, emb = learner(torch.randn(2, 3, 224, 224), return_embedding = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_Feah5IXb4S"
      },
      "outputs": [],
      "source": [
        "learner.online_encoder.get_representation(torch.randn(1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXI3EVY_lgEN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu_PAlO4pV5y"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "from torchvision.io import read_image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def pad(img):\n",
        "    pad_h = max(img.size(1), img.size(2)) - img.size(1)\n",
        "    pad_w = max(img.size(1), img.size(2)) - img.size(2)\n",
        "    img = torch.nn.functional.pad(img, (0, pad_w, 0, pad_h, 0, 0))\n",
        "    img = T.Resize(256)(img)\n",
        "    return img\n",
        "train[\"emb\"] = None\n",
        "mask = train['is_known_id']\n",
        "with torch.no_grad():\n",
        "    for i, row in tqdm(train[mask].iterrows(), total=train[mask].shape[0]):\n",
        "        img = read_image(f\"turtle_recall/images/{row['image_id']}.JPG\") / 255.\n",
        "        img = pad(img)\n",
        "        emb = learner.online_encoder.get_representation(img.unsqueeze(0))\n",
        "        # print(train.loc[i])\n",
        "        train.loc[i, 'emb'] = [emb.cpu().numpy()]\n",
        "        # print(train)\n",
        "        # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgzSfWB3iyZi"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRSFJltdVDqt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "from tqdm import trange\n",
        "\n",
        "def dist(a, b):\n",
        "    return np.dot(a[0] - b[0], a[0] - b[0])\n",
        "\n",
        "new_mask = ~train.image_location.isna()\n",
        "\n",
        "tp, tn, fp, fn = 0, 0, 0, 0\n",
        "for i in trange(100000):\n",
        "    rows = train[new_mask].sample(2)\n",
        "    if rows.iloc[0]['image_location'].lower()!=rows.iloc[1]['image_location'].lower():\n",
        "        continue\n",
        "\n",
        "    d = dist(rows.iloc[0]['emb'], rows.iloc[1]['emb'])\n",
        "    \n",
        "    if rows.iloc[0]['turtle_id']!=rows.iloc[1]['turtle_id']:\n",
        "        if d < 1:\n",
        "            fp+=1\n",
        "        else:\n",
        "            tn+=1\n",
        "    else:\n",
        "        if d < 1:\n",
        "            tp+=1\n",
        "        else:\n",
        "            fn+=1\n",
        "    \n",
        "    # img1 = read_image(f\"turtle_recall/images/{rows.iloc[0]['image_id']}.JPG\")\n",
        "    # img2 = read_image(f\"turtle_recall/images/{rows.iloc[1]['image_id']}.JPG\")\n",
        "    # plt.subplot(1, 2, 1)\n",
        "    # plt.imshow(img1.numpy().transpose((1, 2, 0)))\n",
        "    # plt.subplot(1, 2, 2)\n",
        "    # plt.imshow(img2.numpy().transpose((1, 2, 0)))\n",
        "    # plt.show()\n",
        "\n",
        "    # print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7M5XR_Pkizn"
      },
      "outputs": [],
      "source": [
        "tp/(tp+tn), tp/(tp+fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdOvlThunGxK"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img2.numpy().transpose((1, 2, 0)))\n",
        "plt.show()\n",
        "plt.imshow(img3.numpy().transpose((1, 2, 0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-PyE1LNnqa9"
      },
      "outputs": [],
      "source": [
        "img1=pad(img1)\n",
        "img2=pad(img2)\n",
        "img3=pad(img3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjse30G7nU9G"
      },
      "outputs": [],
      "source": [
        "_, emb = learner(torch.stack([img1, img2, img3], dim=0), return_embedding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd9Op1NioKxh"
      },
      "outputs": [],
      "source": [
        "torch.dot(emb[0]-emb[1], emb[0]-emb[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFS9TFBRnbNR"
      },
      "outputs": [],
      "source": [
        "torch.dot(emb[0]-emb[2], emb[0]-emb[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11EQoC_no78Q"
      },
      "outputs": [],
      "source": [
        "torch.dot(emb[1]-emb[2], emb[1]-emb[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5mbTlyevRCC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "answ_test = pd.read_csv(\"../submission (35).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(answ_test[\"prediction1\"], bins=101)"
      ],
      "metadata": {
        "id": "l6W1th-k_STb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.data import load_csv\n",
        "\n",
        "train, val, test = load_csv(False)"
      ],
      "metadata": {
        "id": "ZvOlTK8OziW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "groups = test.groupby(\"image_location\").groups\n",
        "for k, v in groups.items():\n",
        "    print(\"\\n\"*10, k)\n",
        "    for i, idx in enumerate(v):\n",
        "        id = test.loc[idx][\"image_id\"]\n",
        "        img = plt.imread(f\"/content/turtles/turtle_recall/images/{id}.JPG\")\n",
        "        plt.imshow(img, 'gray')\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "RLr0KGuhFufE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "id": "-IKnivRHkZ4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhZmPNHcvZvD"
      },
      "outputs": [],
      "source": [
        "preds = train.groupby(by = \"turtle_id\").groups"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.image_id test.image_id"
      ],
      "metadata": {
        "id": "4fTL2Hc4S394"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7m5DRqGv4Gq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def adjust_contrast_brightness(img, contrast:float=1.0, brightness:int=0):\n",
        "    \"\"\"\n",
        "    Adjusts contrast and brightness of an uint8 image.\n",
        "    contrast:   (0.0,  inf) with 1.0 leaving the contrast as is\n",
        "    brightness: [-255, 255] with 0 leaving the brightness as is\n",
        "    \"\"\"\n",
        "    brightness += int(round(255*(1-contrast)/2))\n",
        "    return cv2.addWeighted(img, contrast, img, 0, brightness)\n",
        "\n",
        "for k, v in preds.items():\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    image_ids = []\n",
        "    for i, idx in enumerate(v):\n",
        "        id = train.loc[idx][\"image_id\"]\n",
        "        image_ids.append(id)\n",
        "        img = plt.imread(f\"/content/turtles/turtle_recall/images/{id}.JPG\")\n",
        "        plt.subplot(1, len(v), i+1)\n",
        "        # img = img.mean(axis=-1).astype(np.uint8)\n",
        "\n",
        "        img = adjust_contrast_brightness(img, 5., -5.)\n",
        "\n",
        "        # img = cv2.Canny(img,100,150)\n",
        "        plt.imshow(img, 'gray')\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    print(image_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ScA2AHRxKbk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "turtles.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}